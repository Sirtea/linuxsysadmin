<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<title>Acumulando los logs en un servidor centralizado con Kibana - Linux Sysadmin</title>
	<link rel="stylesheet" href="/style.css" />
	<link rel="icon" href="/favicon.ico" />
	
	<script type="text/javascript" src="//www.FreePrivacyPolicy.com/cookie-consent/releases/3.0.0/cookie-consent.js"></script>
	<script type="text/javascript">
	document.addEventListener('DOMContentLoaded', function () {
		cookieconsent.run({"notice_banner_type":"interstitial","consent_type":"express","palette":"dark","change_preferences_selector":"#changePreferences","language":"es","website_name":"LinuxSysadmin","cookies_policy_url":"https://www.linuxsysadmin.ml/cookies.html"});
	});
	</script>
	<noscript>GDPR Cookie Consent by <a href="https://www.freeprivacypolicy.com/">FreePrivacyPolicy</a></noscript>
	

	<script type="text/plain" cookie-consent="tracking">
	var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
	var doNotTrack = (dnt == "1" || dnt == "yes");
	if (!doNotTrack) {
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-68486572-1', 'auto');
		ga('set', 'anonymizeIp', true);
		ga('send', 'pageview');
	}
	</script>
	</head>
<body>
<div class="menu">
	<a class="important" href="/">Linux Sysadmin</a>
	<a href="/about.html">Sobre mí</a>
	<a href="/curriculum.html">Curriculum Vitae</a>
	<div class="right">
		<a href="/cookies.html">Cookies</a>
		<a href="/categories.html">Categorías</a>
		<a href="/tags.html">Tags</a>
		<a href="/archives.html">Archivos</a>
	</div>
</div>

<h1>Acumulando los logs en un servidor centralizado con Kibana</h1>

<p class="headline">
	<strong>Fecha</strong>: 2017-01-16
	<strong>Tiempo de lectura</strong>: 3 minutos
	<strong>Categoría</strong>: <a href="/category/operaciones.html">Operaciones</a>
	<strong>Tags</strong>: <a href="/tag/elk.html">ELK</a> / <a href="/tag/elastic-search.html">elastic search</a> / <a href="/tag/logstash.html">logstash</a> / <a href="/tag/kibana.html">kibana</a> / <a href="/tag/logs.html">logs</a>
</p>

<p>Buscar en los <em>logs</em> es fácil cuando tenemos una máquina de cada tipo, pero es una actividad muy poco gratificante cuando tenemos un número grande o variable de cada tipo. La mejor manera de tenerlos controlados es hacer que envíen sus <em>logs</em> a un almacén central, para su fácil consulta.</p>
<p>En este artículo se pretende dar a conocer una de estas soluciones de acumulación y búsqueda de <em>logs</em>, conocida como <strong>ELK</strong> (hace poco se renombró a <strong>Elastic Stack</strong>). Se trata de un conjunto de servicios que cooperan para obtener una solución completa:</p>
<ul>
<li><strong>Elastic search</strong>: se trata de la base de datos que almacena todos los <em>logs</em> que se le envían.</li>
<li><strong>Logstash</strong>: Es un agente que envía los <em>logs</em> de varias fuentes al <strong>elastic search</strong>.</li>
<li><strong>Kibana</strong>: Es una interfaz gráfica que nos permite buscar <em>logs</em> y dibujar bonitas gráficas, partiendo de los datos del <strong>elastic search</strong>.</li>
</ul>
<p><img src="/images/the-elk-stack.jpg" alt="Esquema de un ELK"></p>
<p>De esto se puede deducir que vamos a necesitar una instancia de cada tipo, a excepción de <strong>logstash</strong>, que debe ponerse en todos los servidores que recojan <em>logs</em>. Se podría poner, por ejemplo, el <strong>elastic search</strong> y el <strong>kibana</strong> en una misma máquina, dedicada solamente al consumo de los <em>logs</em> de todos los servidores productivos.</p>
<h2>Un ejemplo rápido</h2>
<p>Si miramos en <a href="https://hub.docker.com/">DockerHub</a>, podremos comprobar que las 3 piezas disponen de una imagen que las satisface. Eso nos va a ahorrar mucho tiempo, a costa de las particularidades de cada imagen.</p>
<p>Vamos a poner todas las imágenes en el mismo servidor por economía, pero lo ideal sería un <strong>logstash</strong> por servidor y otro servidor con <strong>elastic search</strong> y <strong>kibana</strong>.</p>
<p>El primer paso es acondicionar la memoria que pueden usar nuestros procesos. Esto se hace porque el <strong>elastic search</strong> consume mucha memoria y va a fallar iniciándose.</p>
<pre><code class="language-bash">gerard@styx:~/docker/elk$ sudo sysctl -w vm.max_map_count=262144
vm.max_map_count = 262144
gerard@styx:~/docker/elk$ 
</code></pre>
<p>La mayoría de imágenes funcionan bien de serie, pero no es el caso de <strong>logstash</strong>, que necesita una configuraciṕon para indicar qué <em>logs</em> recoger, las transformaciones que deben sufrir, y el destino al que ir. Más información en <a href="https://www.elastic.co/guide/en/logstash/current/index.html">la documentación</a>. De momento nos vamos a limitar a recoger todos los ficheros <em>.log</em> recursivamente de la carpeta <em>/logs</em>; esta va a ser un volumen de <em>/var/log</em> del servidor real.</p>
<pre><code class="language-bash">gerard@styx:~/docker/elk$ cat logstash.conf 
input {
  file {
    path =&gt; &quot;/logs/**/*.log&quot;
    start_position =&gt; &quot;beginning&quot;
  }
}

output {
  elasticsearch {
    hosts =&gt; [&quot;elasticsearch:9200&quot;]
  }
}
gerard@styx:~/docker/elk$ 
</code></pre>
<p>Para simplificar el despliegue, vamos a usar <strong>docker-compose</strong>, con algunas variaciones interesantes.</p>
<pre><code class="language-bash">gerard@styx:~/docker/elk$ cat docker-compose.yml 
version: '2'
services:
  elasticsearch:
    image: elasticsearch
    container_name: elasticsearch
    hostname: elasticsearch
  kibana:
    image: kibana
    container_name: kibana
    hostname: kibana
    ports:
      - &quot;5601:5601&quot;
  logstash:
    image: logstash
    container_name: logstash
    hostname: logstash
    volumes:
      - ./logstash.conf:/logstash.conf:ro
      - /var/log:/logs:ro
    user: root
    command: [bash, -c, &quot;logstash -f /logstash.conf&quot;]
gerard@styx:~/docker/elk$ 
</code></pre>
<p>Se hace notar especialmente que publicamos el puerto del <strong>kibana</strong>, para poderlo ver cómodamente en nuestro navegador. Aparte de esto, vamos a poner el fichero de configuración de <strong>logstash</strong> como un volumen local, tal como la carpeta de <em>logs</em>. Un último detalle es que modificamos el comando a ejecutar para que el <em>entrypoint</em> que viene por defecto no nos fuerce el usuario <em>logstash</em>, puesto que entonces no podríamos leer muchos de los <em>logs</em>.</p>
<pre><code class="language-bash">gerard@styx:~/docker/elk$ docker-compose up -d
Creating network &quot;elk_default&quot; with the default driver
Creating elasticsearch
Creating logstash
Creating kibana
gerard@styx:~/docker/elk$ 
</code></pre>
<p>Solo nos falta acceder a la interfaz del <strong>Kibana</strong> en <code>http://localhost:5601/</code> y disfrutar del resultado.</p>
<p><img src="/images/kibana-frontend.jpg" alt="Frontend de Kibana"></p>


<p class="footer">Copyright &copy; 2015-2021 | Gerard Monells | <a href="https://github.com/sirtea">GitHub</a></p>

</body>
</html>
